{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Activation\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "import datetime\n",
    "import cx_Oracle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Oracle DB 접속 정보 (반드시 자신의 환경에 맞게 수정!) ---\n",
    "DB_USERNAME = \"system\"  # <<--- 실제 사용자 이름으로 변경\n",
    "DB_PASSWORD = \"1234\"    # <<--- 실제 비밀번호로 변경\n",
    "DB_DSN = \"localhost:1522/xe\" # <<--- 실제 DSN으로 변경 (예: localhost:1521/XE 또는 localhost:1521/ORCLPDB1)\n",
    "\n",
    "TABLE_NAME_ETH = \"ETH_PRICES_DATA\" # SQL Developer에서 생성한 ETH 테이블 이름 (대문자 가정)\n",
    "\n",
    "# 모델 및 로그 저장 경로 설정\n",
    "LOG_DIR = 'logs_eth' \n",
    "MODEL_SAVE_DIR = 'models_eth'\n",
    "\n",
    "if not os.path.exists(LOG_DIR):\n",
    "    os.makedirs(LOG_DIR)\n",
    "    print(f\"'{LOG_DIR}' 폴더 생성 완료\")\n",
    "if not os.path.exists(MODEL_SAVE_DIR):\n",
    "    os.makedirs(MODEL_SAVE_DIR)\n",
    "    print(f\"'{MODEL_SAVE_DIR}' 폴더 생성 완료\")\n",
    "\n",
    "# Instant Client 경로 설정 (필요한 경우 주석 해제 및 경로 수정)\n",
    "# if os.name == 'nt': # Windows 예시\n",
    "#     try:\n",
    "#         # cx_Oracle.init_oracle_client(lib_dir=r\"C:\\oracle\\instantclient_19_19\") # <<--- 실제 경로로 변경\n",
    "#         print(\"Oracle Instant Client 초기화 시도 (Windows).\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Oracle Instant Client 초기화 실패 (Windows): {e}\")\n",
    "# elif os.name == 'posix': # macOS / Linux\n",
    "#     pass # 환경 변수 (LD_LIBRARY_PATH 또는 DYLD_LIBRARY_PATH) 사용 권장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oracle DB (localhost:1522/xe)에 성공적으로 연결되었습니다.\n",
      "DB 테이블 'ETH_PRICES_DATA'에서 데이터 로드 완료.\n",
      "\n",
      "로드 및 전처리 후 Data Head:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlgod\\AppData\\Local\\Temp\\ipykernel_4860\\4102438284.py:21: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data = pd.read_sql_query(query_eth, conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Market Cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>307.38</td>\n",
       "      <td>310.55</td>\n",
       "      <td>305.88</td>\n",
       "      <td>305.88</td>\n",
       "      <td>369583008.0</td>\n",
       "      <td>2.933152e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>305.76</td>\n",
       "      <td>306.40</td>\n",
       "      <td>290.58</td>\n",
       "      <td>291.69</td>\n",
       "      <td>553864000.0</td>\n",
       "      <td>2.918359e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-02</td>\n",
       "      <td>290.73</td>\n",
       "      <td>293.91</td>\n",
       "      <td>281.17</td>\n",
       "      <td>287.43</td>\n",
       "      <td>904900992.0</td>\n",
       "      <td>2.775424e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-03</td>\n",
       "      <td>288.50</td>\n",
       "      <td>308.31</td>\n",
       "      <td>287.69</td>\n",
       "      <td>305.71</td>\n",
       "      <td>646339968.0</td>\n",
       "      <td>2.754741e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-04</td>\n",
       "      <td>305.48</td>\n",
       "      <td>305.48</td>\n",
       "      <td>295.80</td>\n",
       "      <td>300.47</td>\n",
       "      <td>416479008.0</td>\n",
       "      <td>2.917535e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    Open    High     Low   Close       Volume    Market Cap\n",
       "0 2017-10-31  307.38  310.55  305.88  305.88  369583008.0  2.933152e+10\n",
       "1 2017-11-01  305.76  306.40  290.58  291.69  553864000.0  2.918359e+10\n",
       "2 2017-11-02  290.73  293.91  281.17  287.43  904900992.0  2.775424e+10\n",
       "3 2017-11-03  288.50  308.31  287.69  305.71  646339968.0  2.754741e+10\n",
       "4 2017-11-04  305.48  305.48  295.80  300.47  416479008.0  2.917535e+10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "로드 및 전처리 후 Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 365 entries, 0 to 364\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   Date        365 non-null    datetime64[ns]\n",
      " 1   Open        365 non-null    float64       \n",
      " 2   High        365 non-null    float64       \n",
      " 3   Low         365 non-null    float64       \n",
      " 4   Close       365 non-null    float64       \n",
      " 5   Volume      365 non-null    float64       \n",
      " 6   Market Cap  365 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(6)\n",
      "memory usage: 20.1 KB\n",
      "Oracle DB 연결이 닫혔습니다.\n"
     ]
    }
   ],
   "source": [
    "conn = None\n",
    "data = pd.DataFrame() # 빈 DataFrame으로 초기화\n",
    "\n",
    "try:\n",
    "    conn = cx_Oracle.connect(user=DB_USERNAME, password=DB_PASSWORD, dsn=DB_DSN, encoding=\"UTF-8\")\n",
    "    print(f\"Oracle DB ({DB_DSN})에 성공적으로 연결되었습니다.\")\n",
    "    \n",
    "    # 컬럼명을 노트북의 원래 CSV 컬럼명과 유사하게 AS 처리 (따옴표로 감싸서 대소문자 구분)\n",
    "    query_eth = f\"\"\"\n",
    "        SELECT \n",
    "            TRADE_DATE AS \"Date\", \n",
    "            OPEN_PRICE AS \"Open\", \n",
    "            HIGH_PRICE AS \"High\", \n",
    "            LOW_PRICE AS \"Low\", \n",
    "            CLOSE_PRICE AS \"Close\", \n",
    "            TRADE_VOLUME_TEXT AS \"Volume\",\n",
    "            MARKET_CAP_TEXT AS \"Market Cap\"\n",
    "        FROM {TABLE_NAME_ETH} \n",
    "        ORDER BY TRADE_DATE ASC\n",
    "    \"\"\"\n",
    "    data = pd.read_sql_query(query_eth, conn)\n",
    "    \n",
    "    if not data.empty:\n",
    "        print(f\"DB 테이블 '{TABLE_NAME_ETH}'에서 데이터 로드 완료.\")\n",
    "        \n",
    "        data['Date'] = pd.to_datetime(data['Date'])\n",
    "        \n",
    "        def clean_eth_numeric_text(value):\n",
    "            if pd.isna(value) or not isinstance(value, str):\n",
    "                return float(value) if isinstance(value, (int, float)) else np.nan\n",
    "            try:\n",
    "                return float(value.replace(',', ''))\n",
    "            except (ValueError, AttributeError):\n",
    "                return np.nan\n",
    "        \n",
    "        data['Volume'] = data['Volume'].apply(clean_eth_numeric_text)\n",
    "        data['Market Cap'] = data['Market Cap'].apply(clean_eth_numeric_text)\n",
    "\n",
    "        for col in ['Open', 'High', 'Low', 'Close']:\n",
    "             data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "        \n",
    "        essential_cols = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "        data.dropna(subset=essential_cols, inplace=True)\n",
    "        data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        print(\"\\n로드 및 전처리 후 Data Head:\")\n",
    "        # Jupyter Notebook 환경에서는 display() 함수가 더 예쁘게 출력합니다.\n",
    "        # 일반 Python 스크립트에서는 print(data.head()) 사용\n",
    "        from IPython.display import display \n",
    "        display(data.head())\n",
    "        print(\"\\n로드 및 전처리 후 Data Info:\")\n",
    "        data.info()\n",
    "    else:\n",
    "        print(f\"경고: DB 테이블 '{TABLE_NAME_ETH}'에서 데이터를 가져오지 못했거나 데이터가 없습니다.\")\n",
    "\n",
    "except cx_Oracle.Error as e:\n",
    "    error_obj, = e.args\n",
    "    print(f\"Oracle DB 오류: {error_obj.code} - {error_obj.message}\")\n",
    "except Exception as e:\n",
    "    print(f\"데이터 로드 또는 처리 중 오류: {e}\")\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()\n",
    "        print(\"Oracle DB 연결이 닫혔습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 코드 셀 4 시작 ---\n",
      "입력 data DataFrame 비어있는지: False\n",
      "입력 data DataFrame 행 개수: 365\n",
      "mid_prices 생성 완료 (NaN 처리 후), 길이: 365\n",
      "sequence_length: 51, 생성 가능한 최대 시퀀스 수: 315\n",
      "생성된 시퀀스 개수 (result 리스트 길이): 315\n",
      "normalize_windows: 입력 윈도우 315개 중 건너뛴 윈도우 개수 = 0\n",
      "정규화된 시퀀스 형태 (result_normalized.shape): (315, 51)\n",
      "학습/테스트 분할 기준 row 인덱스 (0부터 시작): 284 (즉, train은 [:row], test는 [row:])\n",
      "\n",
      "--- 코드 셀 4 종료 ---\n",
      "x_train 형태: (284, 50, 1)\n",
      "y_train 형태: (284,)\n",
      "x_test 형태: (31, 50, 1)\n",
      "y_test 형태: (31,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlgod\\AppData\\Local\\Temp\\ipykernel_4860\\2116145814.py:22: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  mid_prices_series.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\dlgod\\AppData\\Local\\Temp\\ipykernel_4860\\2116145814.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  mid_prices_series.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 변수 초기화 (이 셀이 여러 번 실행될 경우를 대비)\n",
    "x_train, y_train, x_test, y_test = (None, None, None, None)\n",
    "mid_prices, result, result_normalized = (None, None, None) # 중간 변수들도 초기화\n",
    "seq_len = 50 \n",
    "\n",
    "print(f\"\\n--- 코드 셀 4 시작 ---\")\n",
    "print(f\"입력 data DataFrame 비어있는지: {data.empty}\")\n",
    "if not data.empty:\n",
    "    print(f\"입력 data DataFrame 행 개수: {len(data)}\")\n",
    "\n",
    "# data DataFrame이 존재하고, 필요한 'High', 'Low' 컬럼이 있는지, 그리고 데이터가 있는지 확인\n",
    "if not data.empty and \\\n",
    "   all(col in data.columns for col in ['High', 'Low']) and \\\n",
    "   pd.notna(data['High']).any() and pd.notna(data['Low']).any(): # NaN만 있는 경우가 아닌지 확인\n",
    "\n",
    "    high_prices = data['High'].values\n",
    "    low_prices = data['Low'].values\n",
    "    mid_prices = (high_prices + low_prices) / 2\n",
    "    \n",
    "    # mid_prices에 NaN이 있다면, 이후 계산에 문제가 될 수 있으므로 처리 (예: ffill 후 bfill)\n",
    "    mid_prices_series = pd.Series(mid_prices)\n",
    "    mid_prices_series.fillna(method='ffill', inplace=True)\n",
    "    mid_prices_series.fillna(method='bfill', inplace=True)\n",
    "    mid_prices_series.dropna(inplace=True) # 그래도 NaN이 있다면 해당 부분 제거\n",
    "    mid_prices = mid_prices_series.values\n",
    "    \n",
    "    print(f\"mid_prices 생성 완료 (NaN 처리 후), 길이: {len(mid_prices)}\")\n",
    "    \n",
    "    sequence_length = seq_len + 1\n",
    "    \n",
    "    result = []\n",
    "    # 생성 가능한 시퀀스 수 확인\n",
    "    num_possible_sequences = len(mid_prices) - sequence_length + 1\n",
    "    print(f\"sequence_length: {sequence_length}, 생성 가능한 최대 시퀀스 수: {num_possible_sequences}\")\n",
    "\n",
    "    if num_possible_sequences > 0:\n",
    "        for index in range(num_possible_sequences):\n",
    "            result.append(mid_prices[index: index + sequence_length])\n",
    "        print(f\"생성된 시퀀스 개수 (result 리스트 길이): {len(result)}\")\n",
    "    else:\n",
    "        print(\"오류: mid_prices의 길이가 sequence_length보다 짧거나 같아서 시퀀스를 생성할 수 없습니다.\")\n",
    "        result = [] # result를 빈 리스트로 확실히 함\n",
    "\n",
    "    def normalize_windows(window_data):\n",
    "        normalized_data_list = [] # NumPy 배열로 바로 만들기보다 리스트로 먼저 수집\n",
    "        skipped_windows = 0\n",
    "        for i, window_orig in enumerate(window_data):\n",
    "            window = np.array(window_orig, dtype=float) # 부동소수점 연산을 위해 float으로\n",
    "            if pd.isna(window[0]) or window[0] == 0:\n",
    "                # print(f\"경고 (윈도우 {i}): 정규화 기준값(window[0])이 0 또는 NaN. 건너뜁니다: {window[:3]}\")\n",
    "                skipped_windows += 1\n",
    "                continue\n",
    "            \n",
    "            # window 내 NaN 값을 0으로 채우는 것은 정규화에 왜곡을 줄 수 있음. \n",
    "            # 여기서는 이전 단계에서 mid_prices의 NaN을 처리했다고 가정.\n",
    "            # 만약 window 내에 NaN이 있다면, 해당 윈도우를 건너뛰거나 다른 방식으로 처리해야 함.\n",
    "            if np.isnan(window).any():\n",
    "                # print(f\"경고 (윈도우 {i}): 윈도우 내에 NaN 값이 포함되어 있어 건너뜁니다: {window[:3]}\")\n",
    "                skipped_windows += 1\n",
    "                continue\n",
    "\n",
    "            normalized_window = [((p / window[0]) - 1) for p in window]\n",
    "            normalized_data_list.append(normalized_window)\n",
    "        \n",
    "        print(f\"normalize_windows: 입력 윈도우 {len(window_data)}개 중 건너뛴 윈도우 개수 = {skipped_windows}\")\n",
    "        if not normalized_data_list: # 모든 윈도우가 건너뛰어졌다면 빈 배열 반환\n",
    "            return np.array([])\n",
    "        return np.array(normalized_data_list)\n",
    "\n",
    "    if result: # result 리스트에 데이터가 있는 경우\n",
    "        result_normalized = normalize_windows(result)\n",
    "        \n",
    "        if result_normalized.size == 0 or result_normalized.shape[0] == 0: # 정규화 후 유효 데이터 없는 경우\n",
    "            print(\"오류: 정규화 후 유효한 데이터가 없습니다. 정규화 로직 또는 입력 데이터를 확인하세요.\")\n",
    "        else:\n",
    "            print(f\"정규화된 시퀀스 형태 (result_normalized.shape): {result_normalized.shape}\")\n",
    "            \n",
    "            # 학습/테스트 데이터 분할 (최소한 테스트셋에 1개 이상의 샘플이 있도록 조정)\n",
    "            n_samples = result_normalized.shape[0]\n",
    "            if n_samples < 2: # 최소 2개의 샘플은 있어야 학습/테스트 분할 의미가 있음\n",
    "                print(\"오류: 정규화된 샘플 수가 너무 적어 학습/테스트 분할이 불가능합니다.\")\n",
    "            else:\n",
    "                row = int(round(n_samples * 0.9))\n",
    "                # 테스트셋이 최소 1개는 있도록 row 조정 (row가 전체 샘플 수와 같아지면 안 됨)\n",
    "                if row >= n_samples: \n",
    "                    row = n_samples - 1 \n",
    "                \n",
    "                print(f\"학습/테스트 분할 기준 row 인덱스 (0부터 시작): {row} (즉, train은 [:row], test는 [row:])\")\n",
    "            \n",
    "                train = result_normalized[:row, :]\n",
    "                \n",
    "                if train.shape[0] > 0: # 학습 데이터가 실제로 생성되었는지 확인\n",
    "                    if train.shape[0] > 1: # 1개 초과일 때만 셔플\n",
    "                        np.random.shuffle(train)\n",
    "                    x_train = train[:, :-1]\n",
    "                    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "                    y_train = train[:, -1]\n",
    "                else:\n",
    "                    print(\"오류: train 데이터셋이 비어있습니다.\")\n",
    "\n",
    "                if n_samples > row: # 테스트 데이터셋 생성 가능 여부\n",
    "                    x_test = result_normalized[row:, :-1]\n",
    "                    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "                    y_test = result_normalized[row:, -1]\n",
    "                else:\n",
    "                    print(\"오류: test 데이터셋을 만들 수 없습니다 (분할할 데이터 부족).\")\n",
    "\n",
    "    else: # result 리스트가 비어있는 경우\n",
    "        print(\"오류: 시퀀스 데이터(result)가 생성되지 않았습니다 (mid_prices 길이 부족 또는 기타 문제).\")\n",
    "else: # data DataFrame이 비어있거나 필요한 컬럼이 없는 경우\n",
    "    print(\"오류: 데이터가 비어있거나 필요한 컬럼('High', 'Low')이 없어 특징 생성을 건너뜁니다.\")\n",
    "\n",
    "# 최종적으로 생성된 변수들의 상태 출력\n",
    "print(f\"\\n--- 코드 셀 4 종료 ---\")\n",
    "print(f\"x_train 형태: {x_train.shape if x_train is not None else 'None'}\")\n",
    "print(f\"y_train 형태: {y_train.shape if y_train is not None else 'None'}\")\n",
    "print(f\"x_test 형태: {x_test.shape if x_test is not None else 'None'}\")\n",
    "print(f\"y_test 형태: {y_test.shape if y_test is not None else 'None'}\")\n",
    "\n",
    "if x_train is not None and np.isnan(x_train).any(): print(\"경고: x_train에 NaN 값이 포함되어 있습니다!\")\n",
    "if y_train is not None and np.isnan(y_train).any(): print(\"경고: y_train에 NaN 값이 포함되어 있습니다!\")\n",
    "if x_test is not None and np.isnan(x_test).any(): print(\"경고: x_test에 NaN 값이 포함되어 있습니다!\")\n",
    "if y_test is not None and np.isnan(y_test).any(): print(\"경고: y_test에 NaN 값이 포함되어 있습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "모델 요약:\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 50, 50)            10400     \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 64)                29440     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39905 (155.88 KB)\n",
      "Trainable params: 39905 (155.88 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = None \n",
    "if x_train is not None and x_train.shape[0] > 0 and y_train is not None: \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=(seq_len, 1)))\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(LSTM(64, return_sequences=False))\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer='rmsprop') # 원본 노트북에서는 rmsprop 사용\n",
    "    print(\"\\n모델 요약:\")\n",
    "    model.summary()\n",
    "else:\n",
    "    print(\"학습 데이터가 충분하지 않아 모델을 생성할 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델, 테스트 데이터, 또는 학습 이력이 없어 예측 및 시각화를 수행할 수 없습니다.\n"
     ]
    }
   ],
   "source": [
    "history = None # history 변수를 셀 시작 시 None으로 초기화\n",
    "if model is not None and \\\n",
    "   x_train is not None and x_train.shape[0] > 0 and \\\n",
    "   y_train is not None and y_train.shape[0] > 0 and \\\n",
    "   x_test is not None and x_test.shape[0] > 0 and \\\n",
    "   y_test is not None and y_test.shape[0] > 0: # 모든 필요한 데이터가 준비되었는지 확인\n",
    "\n",
    "    start_time = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "\n",
    "    # 콜백 정의\n",
    "    tensorboard_callback = TensorBoard(log_dir=os.path.join(LOG_DIR, start_time))\n",
    "    \n",
    "    # 모델 파일명에 심볼 이름 포함 (예: eth)\n",
    "    model_filename = f'{start_time}_eth_best_model.h5' # 이 부분은 crypto_eth.ipynb 용입니다.\n",
    "                                                      # stock_samsung.ipynb 에서는 _samsung_ 등으로 변경\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=os.path.join(MODEL_SAVE_DIR, model_filename), \n",
    "        monitor='val_loss', \n",
    "        verbose=1, \n",
    "        save_best_only=True, \n",
    "        mode='min'\n",
    "    )\n",
    "    reduce_lr_callback = ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.2, \n",
    "        patience=5, \n",
    "        verbose=1, \n",
    "        mode='min',\n",
    "        min_lr=1e-7\n",
    "    )\n",
    "\n",
    "    print(\"\\n모델 학습 시작...\")\n",
    "    history = model.fit( # <<--- 바로 이 라인에서 history 변수에 학습 결과가 할당됩니다!\n",
    "        x_train, \n",
    "        y_train,\n",
    "        validation_data=(x_test, y_test),\n",
    "        batch_size=10, \n",
    "        epochs=20,     \n",
    "        callbacks=[tensorboard_callback, checkpoint_callback, reduce_lr_callback]\n",
    "    )\n",
    "    print(\"모델 학습 완료.\")\n",
    "else:\n",
    "    print(\"모델 또는 학습/검증 데이터가 충분하지 않아 학습을 진행할 수 없습니다.\")\n",
    "    # 이 경우 history는 위에서 None으로 초기화된 상태를 유지합니다.\n",
    "    # 디버깅을 위해 각 변수의 상태를 출력해볼 수 있습니다.\n",
    "    print(f\"model is None: {model is None}\")\n",
    "    print(f\"x_train is None or empty: {x_train is None or (x_train is not None and x_train.shape[0] == 0)}\")\n",
    "    print(f\"y_train is None or empty: {y_train is None or (y_train is not None and y_train.shape[0] == 0)}\")\n",
    "    print(f\"x_test is None or empty: {x_test is None or (x_test is not None and x_test.shape[0] == 0)}\")\n",
    "    print(f\"y_test is None or empty: {y_test is None or (y_test is not None and y_test.shape[0] == 0)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
